---
title: "Lecture 14"
subtitle: "Feature Store, Vector DB, Misc."
author: "{{< var instructor.name >}}"
institute:
- "{{< var university.name >}}"
- "{{< var course.semester >}}"
format:
  revealjs:
    slide-number: true
    show-slide-number: print
    theme: custom.scss
    transition: fade
    background-transition: fade
    highlight-style: ayu-mirage
    code-copy: true
---

# Project Discussion

- Any questions about the project presentation?

- Any other project questions?

# Feature Store

## Data preparation accounts for about 80% of the work of data scientists

![](img/Time-1200x511.jpg)
> Source: [Forbes article](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=29309aa46f63)

## Why does this happen?

::: {.incremental}
1. Same set of data sources...
1. Multiple different feature pipelines..
1. Multiple ML models..
1. **But, an overlapping set of ML features..**
1. More problems...
    - Feature duplication
    - Slow time to market
    - Inaccurate predictions
:::

## Solution...

Machine Learning Feature Store

::: {.incremental}
1. For a moment, think of the feature store as a database but for ML features.
1. In a Feature Store
    - Features are now easy to find (GUI, SDK)
    - Feature transformations are reproducible (feature engineering pipelines can now refer to a consistent set of data)
    - ML training pipeline has a reliable, curated, maintained data source to get training datasets rather than having to look at the data lake directly
    - Low latency lookup for realtime inference
    - Consistent features for training and inference
:::

## Feature Stores you can use

- [Feast: Open Source for Production ML](https://feast.dev/)
- [feathr: A scalable, unified data and AI engineering platform for enterprise](https://github.com/feathr-ai/feathr)
- [Tecton: Feature Platform for Real-Time Machine Learning](https://www.tecton.ai/)
- [Amazon Sagemaker Feature Store](https://aws.amazon.com/sagemaker/feature-store)

# Vector Databases

- Store entities (text, images, audio, video, anything really..) represented as embeddings.
    - Embeddings are numerical representations of entities in high dimensional spaces.
    - Embeddings encode (semantic) meaning associated with the objects.

- Provide fast similarity search between entities (of course represented as vector embeddings).
    - Focus is not on finding the exact match, but most similar matches.


## Why do we need vector databases?

- Central to Generative AI apps.
    - Extend the capabilities of LLMs.
    - Avoid hallucinations.

- Use cases include
    - Product search
    - Troubleshooting and incident response
    - Of course, RAG!

## Algorithms for similarity searh

1. k-Nearest Neighbor (k-NN) 
1. Approximate Nearest Neighbor
    - [Hierarchical Navigable Small Worlds algorithm](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf) (HNSW)
    - [Faiss](https://github.com/facebookresearch/faiss/)

## Langchain and Vector DBs

## Large scale data ingestion






