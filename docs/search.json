[
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "Here are a bunch of resources that will help you in this class. This is a tough and challenging class, but if you put in the hard yards you will learn a lot. I promise you, that you will find me willing to work with you every step of the way.\n\nDue dates are closer than they appear.\n\n\n\n\n\n\n\nPay Attention\n\n\n\nDue dates are closer than they appear. Working with Big Data is tricky, start homeworks early to account for the unknown unknowns that will inevitably show up.\n\n\n\n\nFollow instructions for in the homeworks and lab assignments. The homeworks and labs require the output generated by your code to be in a specific format (JSON usually), in a specifically named file with specifically named fields. Your homeworks are graded by an autograder program (so I wrote code to grade the output of your code) and the autograder expects to see the output in a certain prescribed way and if it does not find that then it deducts points. I do manually review all grades once the autograder has done its job. This is important not only for this class but probably more so going forward when the output your code produces will be consumed by both humans and machines."
  },
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Labs",
    "section": "",
    "text": "Lab\nThe lab for the class would involve a hands-on coding assignment provided through GitHub Classroom. You will start the lab in-class, myself and the TAs would be helping you with any questions with the lab and then you would need to turn in the lab by checking in your code and results in the GitHub repo (you will have until next class for this, but usually you would be able to do this much sooner)."
  },
  {
    "objectID": "labs/11-labs.html",
    "href": "labs/11-labs.html",
    "title": "Lambda & Docker",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/11-labs.html#hello-world-lambda",
    "href": "labs/11-labs.html#hello-world-lambda",
    "title": "Lambda & Docker",
    "section": "“Hello World” Lambda",
    "text": "“Hello World” Lambda\nLaunch AWS Academy and get to the AWS Console. Find the Lambda service from the search bar. \nThe dashboard shows the Lambda functions that have been made, some metrics on Lambda usage. Click on the orange Create Function button.\n\nHere you have to fill out the details for your Lambda function. There are several parts to set up.\n\nYou will leave the default option Author from scratch so that you can code directly from the Lambda service.\nSet your Function name as my-first-lambda.\nChoose your Runtime as Python 3.9\nClick on the Change default execution role dropdown, then select Use an existing role option, and finally pick the existing role LabRole. Once you have done these four things, click on the orange Create function button.\n\n\nYou now have your environment for Lambda! In the upper function overview tab, you can select a variety of triggers and destinations for the Lambda. We will leave these alone for now. You can explore both on your own time to see the options.\nLet’s start with the basic test of the “Hello World” code that was provided in the Python code. Click on the orange Test button.\n\nThis will launch a popup to configure your event. You can submit a JSON payload to the test that will mimic input data that the Lambda function can process. Start off by setting Event name to mytest. Then you can leave the Event JSON for now, but you will come back to it for future iterations of experimentation. Click on the orange save button.\n\nClick on the orange test button again. If you click on the arrow then you can choose to change or make a new test environment like you did on the previous step.\n\nYour test will execute, and the results will be shown. Several pieces of info are important:\n\nName of the test that was conducted\nResponse object that the function returned\nFunction logs that include the duration of the function, billed direction, memory max (for pricing), and actual memory used\nStatus in the upper right\n\n\nOPTIONAL - If you wanted to set your Lambda to run on a regular schedule, like a crontab, you will need to add a trigger using EventBridge (CloudWatch Events). The Trigger add would look like this for setting a job to run every day at 10:15am UTC."
  },
  {
    "objectID": "labs/11-labs.html#exploring-the-lambda-file-system---todo",
    "href": "labs/11-labs.html#exploring-the-lambda-file-system---todo",
    "title": "Lambda & Docker",
    "section": "Exploring the Lambda File System - TODO",
    "text": "Exploring the Lambda File System - TODO\nIn this section, you will store three screenshots in your Word doc to show the Lambda responses from a variety of code changes to your Lambda handler function.\nEach time you make a change to the code, you will have to click on the Deploy button and then the orange Test button.\n\n\n1. Use the os or subprocess library in python to view the contents of the root directory. Make a new key in the return dictionary and send as the value the contents of the root directory.\n\n\n2. Return the contents of the event input variable to the lambda_handler function as additional item in the return dictionary\n\n\n3. Return the contents of the context input variable to the lambda_handler function as additional item in the return dictionary. This might take a few tries! How do you deal with objects that need to become strings?"
  },
  {
    "objectID": "labs/11-labs.html#creating-cloud9-environment",
    "href": "labs/11-labs.html#creating-cloud9-environment",
    "title": "Lambda & Docker",
    "section": "Creating Cloud9 Environment",
    "text": "Creating Cloud9 Environment\n\nSearch for cloud9 in the search bar of your AWS console as shown in the figure below.\n\n\n\nOnce on the Cloud9 splash screen, click on the orange button Create environment.\n\n\n\nEnter a Name and description for your environment. The figure below shows sample text you could use. Once you enter your name and description click the orange button Next step.\n\n\n\nThere are a few options here. You can leave all of the defaults. Click the orange Next step button.\n\nThe Environment type section lets you pick if you want to spin up a new EC2 machine or connect to existing resources.\nThe Instance type section is to select how large an instance for Cloud9. The small t2.micro instance is fine for Cloud9.\nThe Platform section is for selecting the operating system for your new instance.\nThe Cost-saving setting option is set so your instance will hibernate after 30 minutes so you are not charged for the instance 24/7. This is a major problem for cloud services because you can run up a bill quite quickly!\nThe IAM role is for managing permissions to AWS resources like S3. Cloud9 setup will make a new role automatically.\n\n\n\n\nThis screen shows the summary of the selections made for naming and configuring the environment. Click the orange Create environment button.\n\n\n\nThe environment will be configured for you. This takes a few minutes.\n\n\nOnce the environment setup screen goes away then you are ready to use Cloud9. If you get a warning message, just click “OK”."
  },
  {
    "objectID": "labs/11-labs.html#setting-up-basic-docker-images-in-cloud9",
    "href": "labs/11-labs.html#setting-up-basic-docker-images-in-cloud9",
    "title": "Lambda & Docker",
    "section": "Setting up Basic Docker Images in Cloud9",
    "text": "Setting up Basic Docker Images in Cloud9\nDocker image building in Cloud9 is easy since the docker package is already set up. You just have to write some code and run Linux commands!\n\nStart off by making a new folder on the lefthand folder sidebar. Call it something simple like docker-lambda-env.\nOnce you have the folder created, create three files in that folder called Dockerfile, app.py, and requirements.txt.\nThe results should look like the below and have the symbols change automatically:\n\n\n\nOpen up the Dockerfile and add the following text (note the # lines are comments just like python!)\n\n# syntax=docker/dockerfile:1\n\n# adapted from https://www.philschmid.de/aws-lambda-with-custom-docker-image\n# https://docs.aws.amazon.com/lambda/latest/dg/python-image.html\nFROM python:3.9-slim-buster\n\nCMD [\"python\", \"-c\", \"import platform; print(f\\\"version: {platform.python_version()}\\\")\"]\n\nGo to the terminal and change directories to the location of your Dockerfile. Run the command docker build ./ -t test\n\n\n\nRun the command docker run test to see if your Dockerfile worked!"
  },
  {
    "objectID": "labs/11-labs.html#lambda-docker-image",
    "href": "labs/11-labs.html#lambda-docker-image",
    "title": "Lambda & Docker",
    "section": "Lambda Docker Image",
    "text": "Lambda Docker Image\n\nUse the new Dockerfile contents below for your Dockerfile. Note that this Dockerfile is invoking your requirements.txt file to install any packages from pip and the app.py lambda_handler function to run the python code.\n\n# syntax=docker/dockerfile:1\n\n# adapted from https://www.philschmid.de/aws-lambda-with-custom-docker-image\n# https://docs.aws.amazon.com/lambda/latest/dg/python-image.html\nFROM public.ecr.aws/lambda/python:3.9\n\n# copy requirements file and install necessary packages\nADD requirements.txt ${LAMBDA_TASK_ROOT}\nRUN pip3 install -r ${LAMBDA_TASK_ROOT}/requirements.txt --target \"${LAMBDA_TASK_ROOT}\"\n\n# Copy function code to docker container\nCOPY app.py ${LAMBDA_TASK_ROOT}\n\n# app (name of py file)\n# handler (name of function to execute for lambda job)\nCMD [ \"app.lambda_handler\" ]\n\nNote that the ADD and COPY commands in Docker for this instance are similar. The ADD function is more advanced and can auto-extract compressed files into the image.\nSet up your python file app.py with a function called lambda_handler that accepts the event and context arguments. Wait, we have already done this in basic Lambda! Copy your function from the Lambda service. This will ensure that the response is the same through basic Lambda and through the Docker Lambda.\n\n\n\nSince you made changes to the Dockerfile and your app.py files, you need to build a new Docker image. Run the command docker build ./ -t lambda-test.\n\n\n\n“Running” the python script requires two steps because the Lambda container is built as a listening service that will execute when there is a payload provided to it.\n\n\nRun the command docker run -p 8080:8080 lambda-test to set up the service on your first terminal tab. This will run the service and listen for triggers. Next, click on the green plus icon and choose New Terminal to launch a new bash terminal.\n\n\n\nIn this second terminal, run the command curl -XPOST \"http://localhost:8080/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'. This should return the same response as what you saw in the Lambda service. Also, go back to the first terminal tab to see the summary of execution message."
  },
  {
    "objectID": "labs/11-labs.html#python-setup",
    "href": "labs/11-labs.html#python-setup",
    "title": "Lambda & Docker",
    "section": "Python Setup",
    "text": "Python Setup\nReturn the price of any stock symbol that is submitted through the payload value for Lambda. For example, I would get the DOW stock price if I ran the command: http://localhost:8080/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"DOW\"}'\n\nThe url has to be dynamic based on the input stock symbol: https://finance.yahoo.com/quote/DOW\nUse the requests and beautifulsoup packages to build the function. Note you will need to add these libraries to the requirements.txt file.\nThe starter code looks like this:\n\n# import libraries\nimport requests\nfrom bs4 import BeautifulSoup\n\n# set url\nurl = f\"https://finance.yahoo.com/quote/DOW\"\n\n# get the url page results\nresponse = requests.get(url)\n\n# try to parse Beautiful Soup\ntry:\n    soup = BeautifulSoup(response.text, \"html.parser\")\nexcept Exception as e: # handle error gracefully\n    return {\n        'statusCode': 200,\n        'body': json.dumps(f'Here is the error message: {e}'),\n        } # send the error message back to the user\n\n# find the price\nprice = soup.find(\"fin-streamer\", {'data-test':\"qsp-price\"}).text\n\nprint(price)\n\nCoding Goals:\n\nAdd try-except framework if the find does not work. What do you return instead?\nMake the url dynamic to the input stock symbol specified\nIntegrate your code into the Lambda framework - event input and response output\n\nHint #1: Try developing using the python console in Cloud9 before integrating into your app.py file.\nHint #2: Once you put the code into the Lambda framework, you will have to build and run to run a development integration.\n\n\nUse the following test inputs to confirm your function can handle all the errors gracefully: APPL, AAPL, appl, DOW, dow.\n\n\nTake a screenshot of your terminal with all 5 test cases and their result and place into your Word doc\n\n\nOnce your code is ready to go with Lambda, add, commit, and push the files (app.py, Dockerfile, requirements.txt) to GitHub. Easiest way to do this is by downloading and uploading through the GitHub website."
  },
  {
    "objectID": "labs/11-labs.html#posting-docker-image-to-ecr",
    "href": "labs/11-labs.html#posting-docker-image-to-ecr",
    "title": "Lambda & Docker",
    "section": "Posting Docker Image to ECR",
    "text": "Posting Docker Image to ECR\nECR stands for Elastic Container Registry.\n\nRun the command aws ecr create-repository --repository-name docker-lambda to make a new repo in the elastic container registry to store your new containers.\nRun the command $(aws ecr get-login --no-include-email --region us-east-1) to grab the login information for your AWS account and store on the Cloud9 EC2 instance. This is bad practice for important accounts, but this account is just for experimenting!\nRun the command cat /home/ec2-user/.docker/config.json to see the contents of the authentication file. Copy the address that looks similar to 565177075063.dkr.ecr.us-east-1.amazonaws.com\nTag the image with the ECR registry by running the command docker tag lambda-test [[THE URL YOU FOUND IN THE LAST STEP]]/docker-lambda\n\nThe example looks like docker tag lambda-test 565177075063.dkr.ecr.us-east-1.amazonaws.com/docker-lambda\nNote that you have to use your own account id, not the one in the example text!\nThe final docker-lambda is referring to the new repository you just built a few commands ago.\n\nPush the image to docker by running the command docker push 565177075063.dkr.ecr.us-east-1.amazonaws.com/docker-lambda\n\n\nRead more about pushing a Docker image to ECR here."
  },
  {
    "objectID": "labs/11-labs.html#docker-setup-in-lambda",
    "href": "labs/11-labs.html#docker-setup-in-lambda",
    "title": "Lambda & Docker",
    "section": "Docker Setup in Lambda",
    "text": "Docker Setup in Lambda\nGo back to the Lambda dashboard by going to this link: https://us-east-1.console.aws.amazon.com/lambda/home?region=us-east-1#/discover. Make a new function by clicking on the orange Create function button.\n\nYou must select the Container image option that is the third item on the top row of options for Lambda.\nName your function container-test\nSet your Execution role like we did earlier so that you use LabRole\nClick on the Browse images button to find the container you just uploaded!\n\n\n\nA popup will launch and you have to select the repository (“docker lambda”) and then your image, which will be called “latest” by default. Click on the orange Select image button.\n\n\nNow you see the same overview page for the Lambda. Since this is a container image and not simple code, we cannot actually preview anything. Just click on the Test tab.\n\nSet a name for your test aapl-test and change the event JSON to look like {\"payload\" : \"AAPL\"}. Once you are satisfied, click on the Save button and then the orange Test button.\n\nThe result of your test will be shown in a green box, and just click on the Details arrow to see the summary. Note that the stock price came back successfully. The billed duration in the example is 2578 ms, with “Init duration” contributing 709.68 ms and the code execution contributing 1867.85 ms. The results are rounded to the nearest millisecond, but are calculated at the 10 microsecond level, WOW!\n\n\nTake a screenshot of the success output from the test you made in Lambda into your Word doc\n\n\nEXTRA CREDIT - 1 points. Modify your app.py to accept multiple stocks comma separated like {“payload” : “AAPL,DOW,MSFT”}"
  },
  {
    "objectID": "labs/11-labs.html#github-classroom",
    "href": "labs/11-labs.html#github-classroom",
    "title": "Lambda & Docker",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/09-labs.html",
    "href": "labs/09-labs.html",
    "title": "Lab 9",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/09-labs.html#github-classroom",
    "href": "labs/09-labs.html#github-classroom",
    "title": "Lab 9",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/07-labs.html",
    "href": "labs/07-labs.html",
    "title": "Lab 7 - SparkSQL",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/07-labs.html#the-right-data-tool",
    "href": "labs/07-labs.html#the-right-data-tool",
    "title": "Lab 7 - SparkSQL",
    "section": "The right data tool…",
    "text": "The right data tool…\n\nSometimes you only need simple solutions to problems. Perfection is the enemy of the good. We’ll walk through a few options when considering a big data job.\nHere are a few options when your data is local:\n\nUsing a single process in R/python\nWriting an R/python function to run in parallel on a single node\nUsing Python cluster tools like Ray or Dask\nUsing PySpark on a single node to development with multiple workers\n\nHere are a few options when your data is distributed\n\nUsing Dask on a cluster\nUsing PySpark on a cluster\n\nHere are a few options for task-specific needs:\n\nHarnessing a specialized solution like GPU data science with RAPIDS. This software is developed so you can conduct your entire data science pipeline on a GPU.\nTensorFlow distributed netural network training with Spark!\nLarge language model processing with Spark!"
  },
  {
    "objectID": "labs/07-labs.html#rdd-vs-pysparksql-dataframe",
    "href": "labs/07-labs.html#rdd-vs-pysparksql-dataframe",
    "title": "Lab 7 - SparkSQL",
    "section": "RDD vs PySparkSQL DataFrame",
    "text": "RDD vs PySparkSQL DataFrame\nRDD (resilient distributed dataset) is an immutable collection of records (rows) of data\n\ngreat for unstructured data\ndoing low-level transformations\n\nPySpark DataFrame is organized into a table with rows and columns. This is just like the format when working in a relational database like Hive.\n\nTwo dimensional table format, great for “standard” datasets\nColumn format means consistent metadata and data typing\nQuery optimization\nSchema is created automatically!"
  },
  {
    "objectID": "labs/07-labs.html#common-actions-in-r-python-pandas-and-pyspark",
    "href": "labs/07-labs.html#common-actions-in-r-python-pandas-and-pyspark",
    "title": "Lab 7 - SparkSQL",
    "section": "Common Actions in R, Python Pandas, and PySpark",
    "text": "Common Actions in R, Python Pandas, and PySpark\nAnything you can do, I can do in parallel!\nTDS big data options\n\nhead(starwars)\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n6 Owen Lars    178   120 brown, gr… light      blue            52   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\nReading in data\n\nR\n\nlibrary(arrow)\nlibrary(dplyr)\n\nstarwars &lt;- arrow::read_parquet('starwars.parquet')\n\n\n\nPandas\n\nimport os\nimport pandas as pd\nstarwars = pd.read_parquet('starwars.parquet')\n\n\n\nPySpark\n\nimport pyspark\nfrom pyspark.sql.functions import udf, lit, col\nfrom pyspark.sql import SparkSession\n\n# configuration for workers\nconfig = pyspark.SparkConf().setAll([('spark.executor.memory', '10g'),\n                             ('spark.executor.cores', '2'),\n                             ('spark.cores.max', '16'),])\n# launch cluster connection\nsc = pyspark.SparkContext(conf = config)\n\n# set up pyspark session\nspark = pyspark.SparkSession.builder.appName('my-test').getOrCreate()\n\nstarwars = spark.read.load('starwars.parquet')\n\n\n\n\nSelecting data variables\n\nR\n\nstarwars_select &lt;- starwars %&gt;% select(name, height, mass)\n\n\n\nPandas\n\nstarwars_select = starwars[['name','height','mass']]\n\n\n\nPySparkSQL\n\nstarwars_select = starwars.select(['name','height','mass'])\n\n\n\n\nFiltering data rows\n\nR\n\nstarwars_filter &lt;- starwars %&gt;% filter(height &gt; 110, \n                                       homeworld == \"Tatooine\")\n\n\n\nPandas\n\nstarwars_filter = starwars[(starwars.height &gt; 110) & \n                        (starwars.homeworld == \"Tatooine\")]\n\n\n\nPySpark\n\nstarwars_filter = starwars[(col('height') &gt; 110) &\n                    (col('homeworld') == \"Tatooine\")]\n\n\n\n\nManipulating data\n\nR\n\nstarwars &lt;- starwars %&gt;% \n    mutate(tatooine_dummy = if_else(homeworld == 'Tatooine',\n                                    TRUE,\n                                    FALSE))\n\n\n\nPandas\n\nstarwars['tatooine_dummy'] = starwars.apply(\n                                  lambda x: True if x.homeworld == 'Tatooine' \n                                        else False, \n                                                axis = 1)\n\n\n\nPySpark\n\nfrom pyspark.sql.types import BooleanType\n@udf(returnType=BooleanType())\ndef dummy_tatooine(x):\n    if x == 'Tatooine':\n        return True\n    else:\n        return False\n\nstarwars = starwars.withColumn('tatooine_dummy', \n                dummy_tatooine(col('homeworld')))\n\n\n\n\nView the head of the data\n\nR\n\nstarwars %&gt;% head(5)\n\n\n\nPandas\n\nstarwars.head(5)\n\n\n\nPySpark\n\nstarwars.take(5) # RDD version\n\nstarwars.show(5) # SQL version\n\n\n\n\nGroup-by mean data\n\nR\n\nstarwars %&gt;% group_by(species) %&gt;% summarize(mean_height = mean(height))\n\n\n\nPandas\n\nstarwars.groupby('species')['height'].mean()\n\n\n\nPySpark\n\nstarwars.groupBy('species').mean('height').collect()\n\n\n\n\nTallest character from each species\n\nR\n\nstarwars %&gt;% group_by(species) %&gt;% filter(height = max(height))\n\n\n\nPandas\n\nstarwars.iloc[starwars.groupby('species').height.idxmax().tolist(),:]\n\nstarwars.sort_values('height',ascending=False).groupby('species').first()\n\n\n\nPySpark\n\ntemp_df = starwars.groupBy('species').agg(f.max('height').alias('height'))\nstarwars.groupBy.join(temp_df,on='height',how='leftsemi').show()\n\nfrom pyspark.sql import Window\nw = Window.partitionBy('species')\nstarwars.withColumn('maxheight', f.max('height').over(w))\\\n    .where(f.col('height') == f.col('maxheight'))\\\n    .drop('maxheight')\\\n    .show()"
  },
  {
    "objectID": "labs/07-labs.html#collecting-data",
    "href": "labs/07-labs.html#collecting-data",
    "title": "Lab 7 - SparkSQL",
    "section": "Collecting Data",
    "text": "Collecting Data\nBe extra careful when using the .collect() function. If you have massive amounts of data, then your spark driver is going to have trouble.\n\nIn general, always run a .count() function to check the number of rows before running .collect(). Alternatively, you can run the command .show(5) or .take(5) to only see the first few rows of data. You never want to bring 10s of millions of rows to your local session. Let the big data live in big data land."
  },
  {
    "objectID": "labs/07-labs.html#github-classroom",
    "href": "labs/07-labs.html#github-classroom",
    "title": "Lab 7 - SparkSQL",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/05-labs.html",
    "href": "labs/05-labs.html",
    "title": "Lab 5",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/05-labs.html#github-classroom",
    "href": "labs/05-labs.html#github-classroom",
    "title": "Lab 5",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/03-labs.html",
    "href": "labs/03-labs.html",
    "title": "Lab 3",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/03-labs.html#github-classroom",
    "href": "labs/03-labs.html#github-classroom",
    "title": "Lab 3",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/01-labs.html",
    "href": "labs/01-labs.html",
    "title": "Lab 1",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet."
  },
  {
    "objectID": "labs/01-labs.html#goals",
    "href": "labs/01-labs.html#goals",
    "title": "Lab 1",
    "section": "Goals",
    "text": "Goals\n\nCreating your public/private ssh key pair and knowing where to find the files\nLearning to use GitHub Codespaces IDE\nLearning the Linux Shell\nBASH Exercise"
  },
  {
    "objectID": "labs/01-labs.html#windows-users",
    "href": "labs/01-labs.html#windows-users",
    "title": "Lab 1",
    "section": "Windows Users",
    "text": "Windows Users\nWindows users will be using the Windows Powershell: &lt;https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/powershell&gt;\nWindows Powershell is most likely installed if you have Windows 10. If you don’t have Powershell, take a look at this article: https://www.howtogeek.com/336775/how-to-enable-and-use-windows-10s-built-in-ssh-commands/ that explains how to install it.\nYou can find Powershell by typing “Powershell” into the search bar:\n\nOnce Powershell is running, this is your terminal:\n\n\nAdditional Powershell Configuration (you must do this!)\nYou need to perform this step **only once** to be able to use agent forwarding which is explained further in the lab.\n\nExit Powershell if running\nStart a new Powershell session using run as Administrator\nEnter the following command (you can cut/paste from here):\n\n\nGet-Service -Name ssh-agent | Set-Service -StartupType Manual\n\nExit Powershell. You should not need to run as administrator going forward."
  },
  {
    "objectID": "labs/01-labs.html#mac-and-linux-users",
    "href": "labs/01-labs.html#mac-and-linux-users",
    "title": "Lab 1",
    "section": "Mac and Linux Users",
    "text": "Mac and Linux Users\nFor Mac and Linux users, you will open up the Terminal.\n\nMacs and Linux have a built in Terminal.\nOr, you can use iTerm app: &lt;https://www.iterm2.com/&gt;\n\nIf you are on Linux (but not on Mac), you can open the terminal by using Ctrl-Alt-T."
  },
  {
    "objectID": "labs/01-labs.html#ssh-keypair-setup",
    "href": "labs/01-labs.html#ssh-keypair-setup",
    "title": "Lab 1",
    "section": "SSH Keypair Setup",
    "text": "SSH Keypair Setup\nWhen you want to connect to a remote machine, the method is called “Secure Shell”. This creates a connection between the local machine (where your terminal window lives) and the “remote” machine (where the commands you will send actually execute). In order for the local and remote machines to authenticate (trust) each other, we have to create a special password-like files called a keypair. It is called a keypair because there is a public version and a private version. Read more about SSH Keys here.\nNOTE: You only need to create your ssh public/private keypair one time only. If you already have a public/private keypair on your laptop let us know.\n\nOpen a terminal (on your laptop) if not already open. By default, every time you open a terminal it will open in your home directory.\nAt the command prompt run the following command: ssh-keygen -t rsa -b 2048 and press enter\nYou will see this prompt, just press enter\n\n\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/User/.ssh/id_rsa):\n\nYou will see this prompt, just press enter\n\n\nCreated directory '/home/User/.ssh'.\nEnter passphrase (empty for no passphrase):\n\nYou will see this prompt, just press enter\n\n\nEnter same passphrase again:\n\nYou will see these messages (your randomart will look different) and your keypair has been created.\n\n\nYour identification has been saved in /home/User_name/.ssh/id_rsa.\nYour public key has been saved in /home/User_name/.ssh/id_rsa.pub.\nThe key fingerprint is:\nSHA256:xPJtMLmJSO73x/NQo3qMpqF6r6St4ONmshS8QZqfmHA User_name@WinDev1802Eval\n\nThe key's randomart image is:\n+---[RSA 2048]----+\n|                 |\n|       . .       |\n| .  . . *        |\n|+. o . = *       |\n|++E o . S o o    |\n|.=+o     . o .   |\n|+oo o o  +o      |\n|+= +.o oo.*.     |\n|*+=++ooooo o.    |\n+----[SHA256]-----+"
  },
  {
    "objectID": "labs/01-labs.html#see-your-key-files",
    "href": "labs/01-labs.html#see-your-key-files",
    "title": "Lab 1",
    "section": "See your key files",
    "text": "See your key files\n\nOpen a terminal if not already open\nChange to your .ssh directory\n\nThis is a hidden directory so if you list your files using ls you won’t see it. For seeing all files, use ls -la.\nTo change into the .ssh directory type cd .ssh\n\nType pwd to print your current working directory.\n\nWindows users in Powershell will see:\n\n\nPS C:\\\\Users\\\\your_name\\.ssh&gt; pwd\n\nPath\n----\nC:\\\\Users\\\\your_name\\.ssh\n\n\nPS C:\\\\Users\\\\your_name\\.ssh&gt;\n\nMac users will see:\n\n\npwd\n/Users/myusername/.ssh\n\nLinux users will see:\n\n\n\\$ pwd\n\n/home/myusername/.ssh\n\nNext, we need to open the new key file we just made.\n\nType ls to list the files in the directory.\n\nWhat is displayed may look different. You will not have a config file unless you have already created one.\n\nType ls -la to list all the files in the directory, even the hidden ones.\n\nWhat is displayed may look different. You will not have a config file unless you have already created one."
  },
  {
    "objectID": "labs/01-labs.html#get-your-public-key-info",
    "href": "labs/01-labs.html#get-your-public-key-info",
    "title": "Lab 1",
    "section": "Get your public key info",
    "text": "Get your public key info\n\nThe file id_rsa is your private key and this file will not leave your computer.\nThe file id_rsa.pub is the public key, whose contents we will upload to cloud services so you authenticate.\nThe known_hosts is a file that gets generated as you connect to different remote systems.\n\nThis is useful so you know you are connecting to the same server as previous times.\n\n\n\n\\$ ls -la\n\ntotal 32\n\ndrwxr-xr-x  6  your_name staff   192 May 29 20:39 .\ndrwxr-xr-x+ 75 your_name staff  2400 May 30 13:35 ..\n-rw-r--r--  1  your_name staff   181 May 29 15:50 config\n-r--------  1  your_name staff  3243 May 29 15:50 id_rsa\n-rw-r--r--  1  your_name staff   742 May 29 15:50 id_rsa.pub\n-rw-r--r--  1  your_name staff   363 May 29 20:42 known_hosts\n\nView the contents of your public_key file by running the command cat id_rsa.pub\n\nWhat is shown is a sample public key, yours will be different\n\n\n\n\\$ cat id_rsa.pub\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnKuIRXwZu0JZH0/Q2XNrYYTaJT7bMtXGhGQaSSOZs6MhQ4SkSbHiygO7RauQf741buLnASzY27GKMMMml6InwfxJWrF60KhNK0r869POQkuZa9v9/cmYcEIzmAJe1xRPABEZ2yfbTG9Wq4sg9cU0mwt1Bx7wiN4QNf0Bak62EC8JWTbcKLduuzO1zabIb5xW9gfR9b4K3HwmqRLl18S8bNsfYQZfvtlwd0mCWQUeuEGbDOgqh//nLIj6DeXdyxbD5xrz79iOAuAK2nXAjNCEtKpxNGQr2Py7aWQjlH+U5laDEHVg4hzmBY7yoZ5eC3Ye45yPqpQA1y8JrbXVhPJRP User\\@WinDev1802Eval"
  },
  {
    "objectID": "labs/01-labs.html#pubkey",
    "href": "labs/01-labs.html#pubkey",
    "title": "Lab 1",
    "section": "Extracting your public key",
    "text": "Extracting your public key\n\nOpen a text editor (Notepad on Windows or Textpad on Mac, NOT MICROSOFT WORD) and select the output of your terminal with all the text from the ssh-rsa beginning all the way to the end, and paste it in your text editor as-is. We will use this in the next step.\n\nYou can also just copy/paste from your terminal screen.\nOn a Mac, you can also copy the contents of the id_rsa.pub file using\n\n\n\npbcopy &lt; id_rsa.pub"
  },
  {
    "objectID": "labs/01-labs.html#adding-ssh-key-to-github",
    "href": "labs/01-labs.html#adding-ssh-key-to-github",
    "title": "Lab 1",
    "section": "Adding SSH Key to GitHub",
    "text": "Adding SSH Key to GitHub\n\na) Create a GitHub Account if you do not already have one\nGo to www.github.com to create a GitHub account if you do not already have one. Your username has to be globally unique, and the email address you use to register GitHub can be any email address you own.\n\n\nb) Upload your Public key to GitHub\n\nLog into to your GitHub account if you are not already logged in\nClick on your profile icon on the top-right of the screen and select Settings from the dropdown\nClick on SSH and GPG keys from the left hand menu\nClick on the New SSH key button on the top-right\nGive your key a name. This is just a name and is meaningful to you.\nPaste the contents of the public key in the Key box. Leave the “Key Type” dropdown as “Authentication Key”.\nClick the Add SSH Key button\n\n\n\nc) Test that your ssh key works with GitHub\n\nOpen a terminal if not already open on your laptop\nAt the command prompt, type ssh -T git@github.com and press enter to test. If it works, you will see something like this, with your GitHub username:\n\n\nThe authenticity of host 'github.com (192.30.253.112)' can't be established.\nRSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added 'github.com,192.30.253.112' (RSA) to the list of known hosts.\nHi wahalulu! You've successfully authenticated, but GitHub does not provide shell access.\nYou are now ready to use ssh authentication with GitHub."
  },
  {
    "objectID": "labs/01-labs.html#create-a-personal-access-token-on-github",
    "href": "labs/01-labs.html#create-a-personal-access-token-on-github",
    "title": "Lab 1",
    "section": "Create a Personal Access Token on GitHub",
    "text": "Create a Personal Access Token on GitHub\n\nLog into to your GitHub account if you are not already logged in\nClick on your profile icon on the top-right of the screen and select Settings from the dropdown\nClick Developer settings\nClick the Personal access tokens tab\nClick the Generate new token button\nEnter a token description (you can call it big-data-class)\nSelect the repo permission, and then click the Generate token button\n\n\n\nCopy the token and save it in a text file. You will need this token later on in the semester and if you lose it you will need to re-generate a token"
  },
  {
    "objectID": "labs/01-labs.html#github-codespaces-ide",
    "href": "labs/01-labs.html#github-codespaces-ide",
    "title": "Lab 1",
    "section": "GitHub Codespaces IDE",
    "text": "GitHub Codespaces IDE\nCodespaces is an integrated developer environment (IDE), which provides you with a VS Code environment with a cloud computing backend. The repository is automatically loaded into your environment and you do not need any additional authentication steps to push to your repo. Read more here about Codespaces.\nIn this lab, we use Codespaces to get you familiar with the Linux terminal.\nYou will not use Codespaces for most of your work this semester. If you were just exploring code or making minor changes to a project, Codespaces could be a simple solution."
  },
  {
    "objectID": "labs/01-labs.html#launching-codespaces",
    "href": "labs/01-labs.html#launching-codespaces",
    "title": "Lab 1",
    "section": "Launching Codespaces",
    "text": "Launching Codespaces\nOpen your Git repo for the lab. Launch Codespaces from your repo by clicking on the green code button, then select “codespaces” then click “Create codespace on main”.\n\nWait for the workspace to be created. It will set up the computing instance with a screen like this."
  },
  {
    "objectID": "labs/01-labs.html#linux-terminal-in-codespaces",
    "href": "labs/01-labs.html#linux-terminal-in-codespaces",
    "title": "Lab 1",
    "section": "Linux Terminal in Codespaces",
    "text": "Linux Terminal in Codespaces\nYou now have full VS Code capabilities. The terminal in Cloud9 is the lower window. You are connected to a cloud computing instance and are able to run BASH commands (along with other programming languages) there.\n\nCheck out the cheat sheet on Linux commands here."
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Lectures and labs",
    "section": "",
    "text": "Each class is divided into two parts: a lecture followed by a lab. Some class optionally have a reading component also that needs to be completed before class.\n\nLecture\nDuring the lecture, I will be going over the slides for that lecture, this would usually include a quick review of the previous class, feedback on a recently graded assignment and then cover the topic of the day.\nThe lecture would usually last about 90 minutes, followed by 5 to 10 minutes break.\n\n\nLab\nThe lab for the class would involve a hands-on coding assignment provided through GitHub Classroom. You will start the lab in-class, myself and the TAs would be helping you with any questions with the lab and then you would need to turn in the lab by checking in your code and results in the GitHub repo (you will have until next class for this, but usually you would be able to do this much sooner)."
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Ray, RAPIDS and DuckDB"
  },
  {
    "objectID": "content/13-content.html#about-todays-class",
    "href": "content/13-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Ray, RAPIDS and DuckDB"
  },
  {
    "objectID": "content/13-content.html#readings",
    "href": "content/13-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture, but you should have completed Lab 0 - Background Skills before this class."
  },
  {
    "objectID": "content/13-content.html#slides",
    "href": "content/13-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/13-content.html#lab",
    "href": "content/13-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/13-content.html#assignment",
    "href": "content/13-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Lambda & Docker."
  },
  {
    "objectID": "content/11-content.html#about-todays-class",
    "href": "content/11-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Lambda & Docker."
  },
  {
    "objectID": "content/11-content.html#readings",
    "href": "content/11-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/11-content.html#slides",
    "href": "content/11-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/11-content.html#lab",
    "href": "content/11-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/11-content.html#assignment",
    "href": "content/11-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 4: NLP with Spark."
  },
  {
    "objectID": "content/09-content.html#about-todays-class",
    "href": "content/09-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 4: NLP with Spark."
  },
  {
    "objectID": "content/09-content.html#readings",
    "href": "content/09-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/09-content.html#slides",
    "href": "content/09-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/09-content.html#lab",
    "href": "content/09-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/09-content.html#assignment",
    "href": "content/09-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 2: Spark DataFrames and SparkSQL."
  },
  {
    "objectID": "content/07-content.html#about-todays-class",
    "href": "content/07-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 2: Spark DataFrames and SparkSQL."
  },
  {
    "objectID": "content/07-content.html#readings",
    "href": "content/07-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/07-content.html#slides",
    "href": "content/07-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/07-content.html#lab",
    "href": "content/07-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/07-content.html#assignment",
    "href": "content/07-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling up data analytics with Dask."
  },
  {
    "objectID": "content/05-content.html#about-todays-class",
    "href": "content/05-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling up data analytics with Dask."
  },
  {
    "objectID": "content/05-content.html#readings",
    "href": "content/05-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nReadings for this lecture (to be completed before this class):\n- Rocklin"
  },
  {
    "objectID": "content/05-content.html#slides",
    "href": "content/05-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/05-content.html#lab",
    "href": "content/05-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/05-content.html#assignment",
    "href": "content/05-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling up on a single machine with Python multiprocessing."
  },
  {
    "objectID": "content/03-content.html#about-todays-class",
    "href": "content/03-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling up on a single machine with Python multiprocessing."
  },
  {
    "objectID": "content/03-content.html#readings",
    "href": "content/03-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nReadings for this lecture (to be completed before this class):\nWolohan Ch. 1,2,5"
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/03-content.html#lab",
    "href": "content/03-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nParallelization with Python and multiprocessing. The lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/03-content.html#assignment",
    "href": "content/03-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Course overview, big data concepts, cloud computing and evolution of cloud technologies."
  },
  {
    "objectID": "content/01-content.html#about-todays-class",
    "href": "content/01-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Course overview, big data concepts, cloud computing and evolution of cloud technologies."
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture, but you should have completed Lab 0 - Background Skills before this class."
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/01-content.html#lab",
    "href": "content/01-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/01-content.html#assignment",
    "href": "content/01-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Introduction to cloud services to be used throughout the semester."
  },
  {
    "objectID": "content/02-content.html#about-todays-class",
    "href": "content/02-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Introduction to cloud services to be used throughout the semester."
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nReadings for this lecture (to be completed before this class):\n- Laberis - What is Cloud\n- Rittinghouse - The Evolution of Cloud"
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/02-content.html#lab",
    "href": "content/02-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nAccessing cloud services, starting and connecting to a virtual machine, S3 commands. The lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/02-content.html#assignment",
    "href": "content/02-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling out: MapReduce, Hadoop, distributed filesystems, Hadoop Streaming."
  },
  {
    "objectID": "content/04-content.html#about-todays-class",
    "href": "content/04-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Scaling out: MapReduce, Hadoop, distributed filesystems, Hadoop Streaming."
  },
  {
    "objectID": "content/04-content.html#readings",
    "href": "content/04-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nReadings for this lecture (to be completed before this class):\n- Wolohan Ch.7\n- Ghemawat et.al - The Google File System\n- Dean, Ghemawat - MapReduce"
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/04-content.html#lab",
    "href": "content/04-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nStarting a cluster, running a Hadoop job with EMR on AWS. The lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/04-content.html#assignment",
    "href": "content/04-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 1: Introduction to Spark, Spark RDDs."
  },
  {
    "objectID": "content/06-content.html#about-todays-class",
    "href": "content/06-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 1: Introduction to Spark, Spark RDDs."
  },
  {
    "objectID": "content/06-content.html#readings",
    "href": "content/06-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nReadings for this lecture (to be completed before this class):\n- Damji et.al Ch.1,2,3"
  },
  {
    "objectID": "content/06-content.html#slides",
    "href": "content/06-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/06-content.html#lab",
    "href": "content/06-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/06-content.html#assignment",
    "href": "content/06-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nGitHub Classroom Link"
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 3: Machine Learning with SparkML."
  },
  {
    "objectID": "content/08-content.html#about-todays-class",
    "href": "content/08-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 3: Machine Learning with SparkML."
  },
  {
    "objectID": "content/08-content.html#readings",
    "href": "content/08-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/08-content.html#slides",
    "href": "content/08-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/08-content.html#lab",
    "href": "content/08-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/08-content.html#assignment",
    "href": "content/08-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 5: Spark Streaming."
  },
  {
    "objectID": "content/10-content.html#about-todays-class",
    "href": "content/10-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Spark 5: Spark Streaming."
  },
  {
    "objectID": "content/10-content.html#readings",
    "href": "content/10-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/10-content.html#slides",
    "href": "content/10-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/10-content.html#lab",
    "href": "content/10-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/10-content.html#assignment",
    "href": "content/10-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Data Engineering."
  },
  {
    "objectID": "content/12-content.html#about-todays-class",
    "href": "content/12-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Data Engineering."
  },
  {
    "objectID": "content/12-content.html#readings",
    "href": "content/12-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture."
  },
  {
    "objectID": "content/12-content.html#slides",
    "href": "content/12-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/12-content.html#lab",
    "href": "content/12-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/12-content.html#assignment",
    "href": "content/12-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "content/14-content.html",
    "href": "content/14-content.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Project discussion and open session."
  },
  {
    "objectID": "content/14-content.html#about-todays-class",
    "href": "content/14-content.html#about-todays-class",
    "title": "PPOL 5206",
    "section": "",
    "text": "Project discussion and open session."
  },
  {
    "objectID": "content/14-content.html#readings",
    "href": "content/14-content.html#readings",
    "title": "PPOL 5206",
    "section": "Readings",
    "text": "Readings\nNo prescribed readings for this lecture, but you should have completed Lab 0 - Background Skills before this class."
  },
  {
    "objectID": "content/14-content.html#slides",
    "href": "content/14-content.html#slides",
    "title": "PPOL 5206",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. You can also click in the slides below and navigate through them with your left and right arrow keys."
  },
  {
    "objectID": "content/14-content.html#lab",
    "href": "content/14-content.html#lab",
    "title": "PPOL 5206",
    "section": "Lab",
    "text": "Lab\nThe lab for today’s lesson is available online as an HTML file."
  },
  {
    "objectID": "content/14-content.html#assignment",
    "href": "content/14-content.html#assignment",
    "title": "PPOL 5206",
    "section": "Assignment",
    "text": "Assignment\nNo assignment for this class."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Big Data Analytics & Cloud Computing\n        ",
    "section": "",
    "text": "Big Data Analytics & Cloud Computing\n        \n        \n            “Learn how to analyze Big Data using cloud computing and technologies such as Concurrency, Spark and others in this hands-on, practical workshop-style course.”\n        \n        \n            PPOL 5206 • Spring 2024Amit Arora, McCourt School of Public PolicyGeorgetown University\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\nInstructor\n\n   Amit Arora\n   Online\n   aa1603@georgetown.edu\n   aarora79\n   Schedule an appointment\n\n\n\nCourse details\n\n   Thursdays\n   January 11 – May 9, 2024\n   6:30–9:00 PM\n   Car Barn 204\n   Slack\n\n\n\nContacting me\nE-mail and Slack are the best ways to get in contact with me. I will try to respond to all course-related e-mails and Slack messages within 24 hours (really), but also remember that life can be busy and chaotic for everyone (including me!), so if I don’t respond right away, don’t worry!"
  },
  {
    "objectID": "labs/02-labs.html",
    "href": "labs/02-labs.html",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #\nFollow these instructions step-by-step to setup your AWS environment. The screenshots may look a bit different than what you are seeing, but the flow is the same."
  },
  {
    "objectID": "labs/02-labs.html#login-into-the-aws-console",
    "href": "labs/02-labs.html#login-into-the-aws-console",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "Login into the AWS Console",
    "text": "Login into the AWS Console\nThe AWS Console is your entry point into the AWS cloud.\n\nClick on the AWS link alongside the ⬤. \nA new tab will open in your browser, this is the AWS Console. \nNote the URL in your browser’s address bar, it will start with the name of the AWS region (such as us-east-1) in which your cloud resources are hosted.\nNote the username on the top right hand corner, this is your Federated Identity. Also note that the you did not have to provide any credentials (username/password) to login into the AWS console. How did this happen?"
  },
  {
    "objectID": "labs/02-labs.html#the-sso-link-to-login-into-the-aws-console-optional",
    "href": "labs/02-labs.html#the-sso-link-to-login-into-the-aws-console-optional",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "The SSO link to login into the AWS Console (Optional)",
    "text": "The SSO link to login into the AWS Console (Optional)\n\nClick on the AWS Details link on the ribbon, this will refresh the text in the panel below, click on AWS SSO button that is now visible on this panel. SSO stands for Single Sign-On i.e. you do not need to provide your credentials everytime you want to login into this page. Clicking on the AWS SSO will download a file on your laptop, keep this file somewhere handy as you will need it in future. \nCopy the contents of the ssourl.txt file that you just downloaded, open an incognito browser window and paste them into the address bar of this incognito browser window. This will log you in into the AWS Console. You will notice that the URL in the address bar changes to the same URL as you had in the previous step.\n\n\n\n\n\n\n\nNote\n\n\n\nThe credentials in the SSO link are short-lived, meaning that they are only valid for a short duration and therefore you cannot use them for a different session.\n\n\n\nSaving AWS CLI credentials for programmatically talking to other AWS services\n\nClick on the AWS CLI button on the AWS Details. \nClick on the Show button. Copy paste the contents you see in a text editor on your laptop and save the file, we will be using these credentials from your EC2 Instance to connect to other AWS services."
  },
  {
    "objectID": "labs/02-labs.html#logging-into-aws-academy-at-a-later-time",
    "href": "labs/02-labs.html#logging-into-aws-academy-at-a-later-time",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "Logging into AWS Academy at a later time",
    "text": "Logging into AWS Academy at a later time\n\nOpen the https://www.awsacademy.com/LMS_Login link in your browser window and click on Student Login.\n\n\n\n\n\n\n\nLogging into the AWS Console at a later time\nTo access the AWS Console in the future, login to https://www.awsacademy.com/LMS_Login, go to Learner Lab -&gt; Modules -&gt; Start Lab.\n\n\n\n\n\n\nNote\n\n\n\nIf you already had an AWS account prior to logging into AWS Academy you would need to login into the AWS Educate AWS account via an Incognito Browser Window."
  },
  {
    "objectID": "labs/02-labs.html#shutting-down-sagemaker-studio",
    "href": "labs/02-labs.html#shutting-down-sagemaker-studio",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "Shutting down SageMaker Studio",
    "text": "Shutting down SageMaker Studio\nIt is important to shutdown SageMaker Studio when not in use so that you do not get billed for it when you are not using it.\n\nClick on File -&gt; Shutdown. \nSelect Shutdown All. \n\n\n\n\n\n\n\nImportant\n\n\n\nAt the end of this lab:\n\nMake sure you shutdown SageMaker Studio.\nMake sure you shutdown EC2 VM.\nMake sure you have ended the lab in AWS Educate by pressing the End Lab button."
  },
  {
    "objectID": "labs/02-labs.html#github-classroom",
    "href": "labs/02-labs.html#github-classroom",
    "title": "Lab 2 Amazon Web Services (AWS) Setup Instructions",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/04-labs.html#hello-world-lambda",
    "href": "labs/04-labs.html#hello-world-lambda",
    "title": "Docker",
    "section": "“Hello World” Lambda",
    "text": "“Hello World” Lambda\nLaunch AWS Academy and get to the AWS Console. Find the Lambda service from the search bar. \nThe dashboard shows the Lambda functions that have been made, some metrics on Lambda usage. Click on the orange Create Function button.\n\n\n\n\n\nHere you have to fill out the details for your Lambda function. There are several parts to set up.\n\nYou will leave the default option Author from scratch so that you can code directly from the Lambda service.\nSet your Function name as test-lambda.\nChoose your Runtime as Python 3.11\nClick on the Change default execution role dropdown, then select Use an existing role option, and finally pick the existing role LabRole.\n\n\n\n\n\n\n\nUnder Advanced Settings check the Enable Function URL checkbox and select None for Auth type. This will create an HTTPS endpoint that you can access from your web browser or cURL command without authentication (in a real world scenario the authentication piece is usually handled by an API Gateway).\n\n\n\n\n\n\n\nNow click on the orange Create function button.\n\nYou now have your environment for Lambda! In the upper function overview tab, you can select a variety of triggers and destinations for the Lambda. We will leave these alone for now. You can explore both on your own time to see the options.\n\n\n\n\n\nLet’s start with the basic test of the “Hello World” code that was provided in the Python code. Click on the blue Test button.\n\n\n\n\n\nThis will launch a popup to configure your event. You can submit a JSON payload to the test that will mimic input data that the Lambda function can process. Start off by setting Event name to mytest. Then you can leave the Event JSON for now, but you will come back to it for future iterations of experimentation. Click on the orange save button.\n\n\n\n\n\nClick on the blue Test button again. If you click on the arrow then you can choose to change or make a new test environment like you did on the previous step.\n\n\n\n\n\nYour test will execute, and the results will be shown. Several pieces of info are important:\n\nName of the test that was conducted\nResponse object that the function returned\nFunction logs that include the duration of the function, billed direction, memory max (for pricing), and actual memory used\nStatus in the upper right\n\n\n\n\n\n\nYou are now ready to invoke your newly deployed Lambda function through your web browser or through cURL. Copy the function URL and paste it in your browser’s address bar.\n\n\n\n\n\nNow try invoking the Lambda from a cURL command (this requires cURL to be available on your machine).\n\n\n\n\n\nOPTIONAL - If you wanted to set your Lambda to run on a regular schedule, like a crontab, you would add a trigger with the Add trigger button in the Function Overview and select EventBridge (CloudWatch Events). The Trigger add would look like this for setting a job to run every day at 10:15am UTC."
  },
  {
    "objectID": "labs/04-labs.html#exploring-the-lambda-file-system---lab-submission-component",
    "href": "labs/04-labs.html#exploring-the-lambda-file-system---lab-submission-component",
    "title": "Docker",
    "section": "Exploring the Lambda File System - LAB SUBMISSION COMPONENT",
    "text": "Exploring the Lambda File System - LAB SUBMISSION COMPONENT\nIn this section, you will a make use of AWS Lambda to see how serverless infrastructure works. For this assignment, you will need to submit a set of JSON files along with other required files.\nIn AWS Lambda, for an output to be generated, you will may use json.dumps to dump a dictionary to the body value in the return statement. This is one of many methods you can use! We encourage you to experiment with few different methods and choose what works the best given your case. A screenshot is attached below for reference. Also note that indent=2 argument for json.dumps, it comes in handy for producting a pretty printed output.\nA dictionary is basically defined as a key:value pair, this is also the building block of json format.\nEach time you make a change to the code, you will have to click on the Deploy button and then the blue Test button.\n\nNote the use of the dict constructor for creating the dictionary. This is an alternate, more readable (arguably slower though) way of creating a Python dictionary. Also note that indent=2 argument for json.dumps, it comes in handy for producting a pretty printed output.\n\n\n\n\n\n\n\nUse the pathlib library and its iterdir() method in Python to view the contents of the root directory (the / is referred to as the root directory). Make a new key in the Lambda called root in the return JSON and send the contents of the root directory. This might take a few tries! How do you deal with objects that need to become strings?\n\n\nHint!: Think how you can pass objects in a string? For this you can use something like this:\n\n\nf'string here {object}'\n\nReturn the contents of the event input variable to the lambda_handler function as additional item in the return JSON as event.\nReturn the python version using the executable() method in the sys library. The key should be py_version.\nReturn the current username using the subprocess library and the whoami shell command. The key should be username.\nNote that all the new keys you are adding to the response should be nested as part of the body. So essentially, the response contains of two keys: a statusCode which specifies if the call successed or failed (a statusCode value other than 200 indicates a failure) and a body key which has the contents of the response.\n\nAfter these have been executed, copy the function URL and put it in lambda-test-url.json\nThe response from the server should be like this:\n{ \"statusCode\": 200,\n  \"body\": {\n    \"message\": \"Hello from Lambda!\",\n    \"root\": \"...\"\n    \"event\": \"...\",\n    \"py_version\": \"...\",\n    \"username\": \"...\"\n  }\n}"
  },
  {
    "objectID": "labs/04-labs.html#part-2--cloud9",
    "href": "labs/04-labs.html#part-2--cloud9",
    "title": "Docker",
    "section": "Part-2- Cloud9",
    "text": "Part-2- Cloud9"
  },
  {
    "objectID": "labs/04-labs.html#creating-cloud9-environment",
    "href": "labs/04-labs.html#creating-cloud9-environment",
    "title": "Docker",
    "section": "Creating Cloud9 Environment",
    "text": "Creating Cloud9 Environment\n\nSearch for cloud9 in the search bar of your AWS console as shown in the figure below.\n\n\n\n\n\n\n\nOnce on the Cloud9 splash screen, click on the orange button Create environment.\n\n\n\n\n\n\n\nEnter a Name for your environment. Leave the description blank. The figure below shows sample text you could use. Once you enter your name, scroll down to the next section.\n\n\n\n\n\n\n\nThere are a few options here. You have to make a few changes.\n\nThe Instance type section is to select how large an instance for Cloud9. Select the t3.small instance type\nThe Platform section is for selecting the operating system for your new instance. Leave as the default\nThe Timeout option is set so your instance will hibernate after 30 minutes so you are not charged for the instance 24/7. This is a major problem for cloud services because you can run up a bill quite quickly! Leave as the default\nIn Network Settings, Connection is how to connect to your instance. Select Secure Shell (SSH)\nFinally, click the orange button Create\n\n\n\n\n\n\n\n\nYou will be sent to the environments page of the Cloud9 service. Your environment is now building. In the table below, for your environment (the row), click on the Open button in Cloud9 IDE column. In the screenshot, we named it cloud9-env.\n\n\n\n\n\n\n\nThe environment will be configured for you. This takes a few minutes.\n\n\n\n\n\n\nOnce the environment setup screen goes away then you are ready to use Cloud9. If you get a warning message, just click “OK”."
  },
  {
    "objectID": "labs/04-labs.html#part-3--docker-lambda",
    "href": "labs/04-labs.html#part-3--docker-lambda",
    "title": "Docker",
    "section": "Part-3- Docker-Lambda",
    "text": "Part-3- Docker-Lambda"
  },
  {
    "objectID": "labs/04-labs.html#setting-up-basic-docker-images-in-cloud9",
    "href": "labs/04-labs.html#setting-up-basic-docker-images-in-cloud9",
    "title": "Docker",
    "section": "Setting up Basic Docker Images in Cloud9",
    "text": "Setting up Basic Docker Images in Cloud9\n\nThis lab will take a lot of time! You will need atleast 5-6 hours on average to work on this lab. Please make sure you start this assignment as soon as possible\n\nDocker image building in Cloud9 is easy since the docker package is already set up. You just have to write some code and run Linux commands!\n\nIn Cloud9, start off by cloning your git repository from either the source control button on the lefthand sidebar or through the terminal.\nIn the root of your repository, create three empty text files in that folder called Dockerfile, app.py, and requirements.txt.\nThe results should look like below and have the symbols change automatically:\n\n\n\nOpen up the Dockerfile and add the following text (note the # lines are comments just like python!)\n\n# syntax=docker/dockerfile:1\n\n# adapted from https://www.philschmid.de/aws-lambda-with-custom-docker-image\n# https://docs.aws.amazon.com/lambda/latest/dg/python-image.html\nFROM python:3.11-slim-buster\n\nCMD [\"python\", \"-c\", \"import platform; print(f\\\"version: {platform.python_version()}\\\")\"]\n\nGo to the terminal and change directories to the location of your Dockerfile. Run the command docker build ./ -t test\n\n\n\nRun the command docker run test to see if your Dockerfile worked!"
  },
  {
    "objectID": "labs/04-labs.html#lambda-docker-imagelab-demonstration",
    "href": "labs/04-labs.html#lambda-docker-imagelab-demonstration",
    "title": "Docker",
    "section": "Lambda Docker Image(Lab-Demonstration)",
    "text": "Lambda Docker Image(Lab-Demonstration)\nNote that this Dockerfile is invoking your requirements.txt file to install any packages from pip and the app.py lambda_handler function to run the python code.\n\nNow you might think how does this requirements.txt file work? Each library which needs to be installed will be listed here. Think of Docker as a virtual environment where you can install any package you need and then you would list them in the requirements.txt file. A small example of this is given in the following screenshot below. When the requirements.txt file has been changed, you will have to build and redeploy the docker image.\n\n\n\n\nrequirements.txt\n\n\n\nUse the new Dockerfile contents below for your Dockerfile.\n\nA few examples of how to build a docker file along with some documentation is given below in this link: https://spacelift.io/blog/dockerfile. You can scroll down to see how a docker commands work and what they do. This will be useful in making this a relatively simple task.\n# syntax=docker/dockerfile:1\n\n# adapted from https://www.philschmid.de/aws-lambda-with-custom-docker-image\n# https://docs.aws.amazon.com/lambda/latest/dg/python-image.html\nFROM public.ecr.aws/lambda/python:3.11\n\n##### copy requirements file and install necessary packages\n\n# ***CODE TO DO***\n# ADD the requirements.txt into the ${LAMBDA_TASK_ROOT} directory in the container\n\nRUN pip3 install -r ${LAMBDA_TASK_ROOT}/requirements.txt --target \"${LAMBDA_TASK_ROOT}\"\n\n##### Copy function code to docker container\n\n# ***CODE TO DO***\n# ADD the app.py file into the ${LAMBDA_TASK_ROOT} directory in the container\n\n##### SET THE COMMAND OF THE CONTAINER FOR THE LAMBDA HANDLER\n# app (name of py file)\n# handler (name of function to execute for lambda job)\nCMD [ \"app.lambda_handler\" ]\n\nNote that the ADD and COPY commands in Docker for this instance are similar. The ADD function is more advanced and can auto-extract compressed files into the image. Please use the given python version for this assignment. This assignment was mainly designed to be used with python 3.11. If you a version of python which is lower, we cannot say if it would be compatible.\nSet up your python file app.py with a function called lambda_handler that accepts the event and context arguments. Wait, we have already done this in basic Lambda! Copy your function from the Lambda service. This will ensure that the response is the same through basic Lambda and through the Docker Lambda.\nSince you made changes to the Dockerfile and your app.py files, you need to build a new Docker image. Run the command docker build ./ -t lambda-test so that you name the image something new.\nThis has to be done every time you make changes to the app.py file or the Dockerfile.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe syntax of docker build is as follows:\ndocker build PATH -t 'CONTAINER NAME'\n\n#Container name can be changed in this instance, but lambda-test is preferred.\n#  -t is a flag which tags the container with a name \n#  In the above command, ./ is the path where the container would be built. \n#  Can you recall where does ./ lead to?\n\n\n\n\nTry running the command docker images to see the images you have in your local environment.\n\n\n\n“Running” the python script requires two steps because the Lambda container is built as a listening service that will execute when there is a payload provided to it.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe syntax of docker run is as follows:\n\ndocker run -p PORT CONTAINER NAME\n\n#-p flag specifies which port needs to be used for the container to start running.\n# CONTAINER NAME can be anything, we defined it to be lambda-test in this scenario.\n\n\n\nRun the command docker run -p 8080:8080 lambda-test to set up the service on your first terminal tab. This will run the service and listen for triggers. Next, click on the green plus icon and choose New Terminal to launch a new bash terminal.\n\n\n\nIn this second terminal, run the command curl -XPOST \"http://localhost:8080/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"hello world!\"}'. This should return the same response as what you saw in the Lambda service. Also, go back to the first terminal tab to see the summary of execution message."
  },
  {
    "objectID": "labs/04-labs.html#python-setup",
    "href": "labs/04-labs.html#python-setup",
    "title": "Docker",
    "section": "Python Setup",
    "text": "Python Setup\nReturn the price of any stock symbol that is submitted through the payload value for Lambda. For example, the goal is to get the DOW stock price if I run the command: http://localhost:8080/2015-03-31/functions/function/invocations\" -d '{\"payload\":\"DOW\"}'\n\nThe url has to be dynamic based on the input stock symbol: https://finance.yahoo.com/quote/DOW\nUse the requests and beautifulsoup packages to build the function. Note you will need to add these libraries to the requirements.txt file.\nStart your app.py file with this start code.\n\nimport os\nimport json\nimport requests\nimport traceback\nfrom bs4 import BeautifulSoup\n\nurl = f\"https://finance.yahoo.com/quote/DOW\"\n\n# need headers to get pull from yahoo finance\nheader = {'Connection': 'keep-alive',\n          'Expires': '-1',\n          'Upgrade-Insecure-Requests': '1',\n          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) \\\n           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'\n          }\n\nresponse = requests.get(url, headers=header)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nprice = soup.find(\"fin-streamer\", {'data-field':\"regularMarketPrice\", 'data-symbol' : stock.upper()}).text\n\nprint(f\"price={price}\")"
  },
  {
    "objectID": "labs/04-labs.html#coding-requirements",
    "href": "labs/04-labs.html#coding-requirements",
    "title": "Docker",
    "section": "Coding Requirements:",
    "text": "Coding Requirements:\n\nAdd a try-except framework if any part of your code errors. Use the command error=traceback.format_exc() to capture the error. What do you return when the function errors instead?\nEnsure that if your function does not receive an input or if it receives an invalid stock ticker that it returns a 404 status code. For no input use the message \"No stock provided\" and for an invalid ticker choose \"Invalid stock provided\"\nMake the url dynamic to the input stock symbol specified\nIntegrate your code into the Lambda framework - event input and response output\nEnsure the response object for a successful request looks like {\"statusCode\" : 200, \"body\" : {\"stock\" : \"A\", \"price\" : \"#####\"}}.\n\n\nPlease use indent = 2 when dumping the response to make sure the response is easily readable\n\n\nHint #1: Try developing using the python console in Cloud9 before integrating into your app.py file. You don’t want to have to build a Docker image every code change, right?\n\nThis process is mainly only for prototyping. You would do this by writing the entire python code first in app.py file, then running the following command in the terminal :\n\n\npython app.py --payload {'payload': 'stock'}\nHint #2: Once you put the code into the Lambda framework, you will have to build and run to complete a development integration.\nHint #3: Implement a basic logger function to see where you might be going wrong? is ther a certain way to pass an input string to the event handler function? Try printing the event out to the console.\n\n\nUse the following test inputs to confirm your function can handle all the errors gracefully: APPL, AAPL, appl, DOW, dow. Unknown tickers need to be handled and case of the ticker should not matter.\nSubmit the bash history where this function is implemented in the file lambda-local-test.txt.\nOnce your code is ready to go with Lambda, add, commit, and push the files (app.py, Dockerfile, requirements.txt) to GitHub."
  },
  {
    "objectID": "labs/04-labs.html#posting-docker-image-to-ecr",
    "href": "labs/04-labs.html#posting-docker-image-to-ecr",
    "title": "Docker",
    "section": "Posting Docker Image to ECR",
    "text": "Posting Docker Image to ECR\nECR stands for Elastic Container Registry.\n\nRun the command aws ecr create-repository --repository-name docker-lambda to make a new repo in the elastic container registry to store your new containers.\nRun the commands to grab info on your AWS account and region.\naws_region=$(aws configure get region)\naws_account_id=$(aws sts get-caller-identity --query 'Account' --output text)\nRun the following command to configure your authentication to talk to the ECR service. Note how we use BASH variable with the $ so that you don’t have to manually enter your region or account id.\naws ecr get-login-password \\\n--region $aws_region \\\n| docker login \\\n--username AWS \\\n--password-stdin $aws_account_id.dkr.ecr.$aws_region.amazonaws.com\nTag the image in the ECR registry by running the command docker tag lambda-docker-build $aws_account_id.dkr.ecr.$aws_region.amazonaws.com/docker-lambda\n\nThe final docker-lambda is referring to the new repository you just built a few commands ago.\n\nPush the image to docker by running the command docker push $aws_account_id.dkr.ecr.$aws_region.amazonaws.com/docker-lambda\n\n\nRead more about pushing a Docker image to ECR here."
  },
  {
    "objectID": "labs/04-labs.html#docker-setup-in-lambda",
    "href": "labs/04-labs.html#docker-setup-in-lambda",
    "title": "Docker",
    "section": "Docker Setup in Lambda",
    "text": "Docker Setup in Lambda\nGo back to the Lambda dashboard by going to this link. Make a new function by clicking on the orange Create function button.\n\nYou must select the Container image option that is the third item on the top row of options for Lambda.\nName your function container-test\nSet your Execution role like we did earlier so that you use LabRole\nClick on the Browse images button to find the container you just uploaded!\n\n\n\nA popup will launch and you have to select the repository (“docker lambda”) and then your image, which will be called “latest” by default. Click on the orange Select image button.\n\n\nNow you see the same overview page for the Lambda. Since this is a container image and not simple code, we cannot actually preview anything. Just click on the Test tab.\n\nSet a name for your test aapl-test and change the event JSON to look like {\"payload\" : \"AAPL\"}. Once you are satisfied, click on the Save button and then the orange Test button.\n\nThe result of your test will be shown in a green box, and just click on the Details arrow to see the summary. Note that the stock price came back successfully. The billed duration in the example is 2578 ms, with “Init duration” contributing 709.68 ms and the code execution contributing 1867.85 ms. The results are rounded to the nearest millisecond, but are calculated at the 10 microsecond level, WOW!"
  },
  {
    "objectID": "labs/06-labs.html",
    "href": "labs/06-labs.html",
    "title": "Lab 6",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/06-labs.html#github-classroom",
    "href": "labs/06-labs.html#github-classroom",
    "title": "Lab 6",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/08-labs.html",
    "href": "labs/08-labs.html",
    "title": "Lab 8",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/08-labs.html#github-classroom",
    "href": "labs/08-labs.html#github-classroom",
    "title": "Lab 8",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/10-labs.html",
    "href": "labs/10-labs.html",
    "title": "Lab 10",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/10-labs.html#github-classroom",
    "href": "labs/10-labs.html#github-classroom",
    "title": "Lab 10",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link"
  },
  {
    "objectID": "labs/13-labs.html",
    "href": "labs/13-labs.html",
    "title": "Lab 13",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  },
  {
    "objectID": "labs/13-labs.html#github-classroom",
    "href": "labs/13-labs.html#github-classroom",
    "title": "Lab 13",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nGitHub Classroom Link - Part 1"
  },
  {
    "objectID": "labs/login-to-saxanet.html",
    "href": "labs/login-to-saxanet.html",
    "title": "PPOL 5206",
    "section": "",
    "text": "Important\n\n\n\nMake sure that you are connected to the Saxanet WiFi network and not the GuestNet network. SSH (TCP port 22) is blocked on GuesNet which means if you are on GuesNet you wil not be able to connect to your cloud VMs or clone repos from GitHub via SSH. Use SaxaNet. #"
  }
]